{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 3004,
          "databundleVersionId": 861823,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31040,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Simple MNIST NN from scratch (numpy, no TF/Keras)",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "LINK TO ORIGINAL :- https://www.kaggle.com/code/ayushsyntax/simple-mnist-nn-from-scratch-numpy-no-tf-keras"
      ],
      "metadata": {
        "id": "YGUKyXRfXVhZ"
      }
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "e5eXBCdDXKSs"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "digit_recognizer_path = kagglehub.competition_download('digit-recognizer')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "Bc8yhgEmXKSv"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T16:28:54.730219Z",
          "iopub.execute_input": "2025-05-25T16:28:54.730515Z",
          "iopub.status.idle": "2025-05-25T16:28:54.737843Z",
          "shell.execute_reply.started": "2025-05-25T16:28:54.730491Z",
          "shell.execute_reply": "2025-05-25T16:28:54.736891Z"
        },
        "id": "P1P009BaXKSw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple MNIST NN from scratch\n",
        "\n",
        "In this notebook, I implemented a simple two-layer neural network and trained it on the MNIST digit recognizer dataset. It's meant to be an instructional example, through which you can understand the underlying math of neural networks better.\n",
        "\n",
        "Here's a video I made explaining all the math and showing my progress as I coded the network: https://youtu.be/w8yWXqWQYmU"
      ],
      "metadata": {
        "id": "6z0IefhvXKSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "data = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T16:28:50.595652Z",
          "iopub.execute_input": "2025-05-25T16:28:50.595977Z",
          "iopub.status.idle": "2025-05-25T16:28:54.728598Z",
          "shell.execute_reply.started": "2025-05-25T16:28:50.595939Z",
          "shell.execute_reply": "2025-05-25T16:28:54.727448Z"
        },
        "id": "VUK6xPLFXKSz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array(data)\n",
        "m, n = data.shape\n",
        "np.random.shuffle(data) # shuffle before splitting into dev and training sets\n",
        "\n",
        "data_dev = data[0:1000].T\n",
        "Y_dev = data_dev[0]\n",
        "X_dev = data_dev[1:n]\n",
        "X_dev = X_dev / 255.\n",
        "\n",
        "data_train = data[1000:m].T\n",
        "Y_train = data_train[0]\n",
        "X_train = data_train[1:n]\n",
        "X_train = X_train / 255.\n",
        "_,m_train = X_train.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T16:29:07.308776Z",
          "iopub.execute_input": "2025-05-25T16:29:07.30911Z",
          "iopub.status.idle": "2025-05-25T16:29:08.240854Z",
          "shell.execute_reply.started": "2025-05-25T16:29:07.309084Z",
          "shell.execute_reply": "2025-05-25T16:29:08.239762Z"
        },
        "id": "CRZ9kOsxXKS0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T16:29:27.335021Z",
          "iopub.execute_input": "2025-05-25T16:29:27.335347Z",
          "iopub.status.idle": "2025-05-25T16:29:27.344035Z",
          "shell.execute_reply.started": "2025-05-25T16:29:27.335322Z",
          "shell.execute_reply": "2025-05-25T16:29:27.342858Z"
        },
        "id": "B5CwaANkXKS1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our NN will have a simple two-layer architecture. Input layer $a^{[0]}$ will have 784 units corresponding to the 784 pixels in each 28x28 input image. A hidden layer $a^{[1]}$ will have 10 units with ReLU activation, and finally our output layer $a^{[2]}$ will have 10 units corresponding to the ten digit classes with softmax activation.\n",
        "\n",
        "**Forward propagation**\n",
        "\n",
        "$$Z^{[1]} = W^{[1]} X + b^{[1]}$$\n",
        "$$A^{[1]} = g_{\\text{ReLU}}(Z^{[1]}))$$\n",
        "$$Z^{[2]} = W^{[2]} A^{[1]} + b^{[2]}$$\n",
        "$$A^{[2]} = g_{\\text{softmax}}(Z^{[2]})$$\n",
        "\n",
        "**Backward propagation**\n",
        "\n",
        "$$dZ^{[2]} = A^{[2]} - Y$$\n",
        "$$dW^{[2]} = \\frac{1}{m} dZ^{[2]} A^{[1]T}$$\n",
        "$$dB^{[2]} = \\frac{1}{m} \\Sigma {dZ^{[2]}}$$\n",
        "$$dZ^{[1]} = W^{[2]T} dZ^{[2]} .* g^{[1]\\prime} (z^{[1]})$$\n",
        "$$dW^{[1]} = \\frac{1}{m} dZ^{[1]} A^{[0]T}$$\n",
        "$$dB^{[1]} = \\frac{1}{m} \\Sigma {dZ^{[1]}}$$\n",
        "\n",
        "**Parameter updates**\n",
        "\n",
        "$$W^{[2]} := W^{[2]} - \\alpha dW^{[2]}$$\n",
        "$$b^{[2]} := b^{[2]} - \\alpha db^{[2]}$$\n",
        "$$W^{[1]} := W^{[1]} - \\alpha dW^{[1]}$$\n",
        "$$b^{[1]} := b^{[1]} - \\alpha db^{[1]}$$\n",
        "\n",
        "**Vars and shapes**\n",
        "\n",
        "Forward prop\n",
        "\n",
        "- $A^{[0]} = X$: 784 x m\n",
        "- $Z^{[1]} \\sim A^{[1]}$: 10 x m\n",
        "- $W^{[1]}$: 10 x 784 (as $W^{[1]} A^{[0]} \\sim Z^{[1]}$)\n",
        "- $B^{[1]}$: 10 x 1\n",
        "- $Z^{[2]} \\sim A^{[2]}$: 10 x m\n",
        "- $W^{[1]}$: 10 x 10 (as $W^{[2]} A^{[1]} \\sim Z^{[2]}$)\n",
        "- $B^{[2]}$: 10 x 1\n",
        "\n",
        "Backprop\n",
        "\n",
        "- $dZ^{[2]}$: 10 x m ($~A^{[2]}$)\n",
        "- $dW^{[2]}$: 10 x 10\n",
        "- $dB^{[2]}$: 10 x 1\n",
        "- $dZ^{[1]}$: 10 x m ($~A^{[1]}$)\n",
        "- $dW^{[1]}$: 10 x 10\n",
        "- $dB^{[1]}$: 10 x 1"
      ],
      "metadata": {
        "id": "SitT7BcQXKS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_params():\n",
        "    W1 = np.random.rand(10, 784) - 0.5\n",
        "    b1 = np.random.rand(10, 1) - 0.5\n",
        "    W2 = np.random.rand(10, 10) - 0.5\n",
        "    b2 = np.random.rand(10, 1) - 0.5\n",
        "    return W1, b1, W2, b2\n",
        "\n",
        "def ReLU(Z):\n",
        "    return np.maximum(Z, 0)\n",
        "\n",
        "def softmax(Z):\n",
        "    A = np.exp(Z) / sum(np.exp(Z))\n",
        "    return A\n",
        "\n",
        "def forward_prop(W1, b1, W2, b2, X):\n",
        "    Z1 = W1.dot(X) + b1\n",
        "    A1 = ReLU(Z1)\n",
        "    Z2 = W2.dot(A1) + b2\n",
        "    A2 = softmax(Z2)\n",
        "    return Z1, A1, Z2, A2\n",
        "\n",
        "def ReLU_deriv(Z):\n",
        "    return Z > 0\n",
        "\n",
        "def one_hot(Y):\n",
        "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
        "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
        "    one_hot_Y = one_hot_Y.T\n",
        "    return one_hot_Y\n",
        "\n",
        "def backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y):\n",
        "    one_hot_Y = one_hot(Y)\n",
        "    dZ2 = A2 - one_hot_Y\n",
        "    dW2 = 1 / m * dZ2.dot(A1.T)\n",
        "    db2 = 1 / m * np.sum(dZ2)\n",
        "    dZ1 = W2.T.dot(dZ2) * ReLU_deriv(Z1)\n",
        "    dW1 = 1 / m * dZ1.dot(X.T)\n",
        "    db1 = 1 / m * np.sum(dZ1)\n",
        "    return dW1, db1, dW2, db2\n",
        "\n",
        "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
        "    W1 = W1 - alpha * dW1\n",
        "    b1 = b1 - alpha * db1\n",
        "    W2 = W2 - alpha * dW2\n",
        "    b2 = b2 - alpha * db2\n",
        "    return W1, b1, W2, b2"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T16:29:50.504086Z",
          "iopub.execute_input": "2025-05-25T16:29:50.504409Z",
          "iopub.status.idle": "2025-05-25T16:29:50.515663Z",
          "shell.execute_reply.started": "2025-05-25T16:29:50.504384Z",
          "shell.execute_reply": "2025-05-25T16:29:50.514506Z"
        },
        "id": "HDGEY7uHXKS3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(A2):\n",
        "    return np.argmax(A2, 0)\n",
        "\n",
        "def get_accuracy(predictions, Y):\n",
        "    print(predictions, Y)\n",
        "    return np.sum(predictions == Y) / Y.size\n",
        "\n",
        "def gradient_descent(X, Y, alpha, iterations):\n",
        "    W1, b1, W2, b2 = init_params()\n",
        "    for i in range(iterations):\n",
        "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
        "        dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y)\n",
        "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
        "        if i % 10 == 0:\n",
        "            print(\"Iteration: \", i)\n",
        "            predictions = get_predictions(A2)\n",
        "            print(get_accuracy(predictions, Y))\n",
        "    return W1, b1, W2, b2"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T16:29:58.769154Z",
          "iopub.execute_input": "2025-05-25T16:29:58.769482Z",
          "iopub.status.idle": "2025-05-25T16:29:58.777114Z",
          "shell.execute_reply.started": "2025-05-25T16:29:58.769454Z",
          "shell.execute_reply": "2025-05-25T16:29:58.776141Z"
        },
        "id": "lP809aTMXKS4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.10, 500)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T16:30:08.491402Z",
          "iopub.execute_input": "2025-05-25T16:30:08.491837Z",
          "iopub.status.idle": "2025-05-25T16:30:54.384047Z",
          "shell.execute_reply.started": "2025-05-25T16:30:08.491806Z",
          "shell.execute_reply": "2025-05-25T16:30:54.382238Z"
        },
        "id": "cqYK-4thXKS5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(X, W1, b1, W2, b2):\n",
        "    _, _, _, A2 = forward_prop(W1, b1, W2, b2, X)\n",
        "    predictions = get_predictions(A2)\n",
        "    return predictions\n",
        "\n",
        "def test_prediction(index, W1, b1, W2, b2):\n",
        "    current_image = X_train[:, index, None]\n",
        "    prediction = make_predictions(X_train[:, index, None], W1, b1, W2, b2)\n",
        "    label = Y_train[index]\n",
        "    print(\"Prediction: \", prediction)\n",
        "    print(\"Label: \", label)\n",
        "\n",
        "    current_image = current_image.reshape((28, 28)) * 255\n",
        "    plt.gray()\n",
        "    plt.imshow(current_image, interpolation='nearest')\n",
        "    plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T16:31:05.078475Z",
          "iopub.execute_input": "2025-05-25T16:31:05.078926Z",
          "iopub.status.idle": "2025-05-25T16:31:05.086036Z",
          "shell.execute_reply.started": "2025-05-25T16:31:05.078897Z",
          "shell.execute_reply": "2025-05-25T16:31:05.085031Z"
        },
        "id": "t9dIBYDNXKS6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_prediction(0, W1, b1, W2, b2)\n",
        "test_prediction(1, W1, b1, W2, b2)\n",
        "test_prediction(2, W1, b1, W2, b2)\n",
        "test_prediction(3, W1, b1, W2, b2)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T16:31:15.85877Z",
          "iopub.execute_input": "2025-05-25T16:31:15.859146Z",
          "iopub.status.idle": "2025-05-25T16:31:16.581099Z",
          "shell.execute_reply.started": "2025-05-25T16:31:15.859118Z",
          "shell.execute_reply": "2025-05-25T16:31:16.580055Z"
        },
        "id": "07ypAvuDXKS6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dev_predictions = make_predictions(X_dev, W1, b1, W2, b2)\n",
        "get_accuracy(dev_predictions, Y_dev)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-25T16:31:46.798896Z",
          "iopub.execute_input": "2025-05-25T16:31:46.799256Z",
          "iopub.status.idle": "2025-05-25T16:31:46.812456Z",
          "shell.execute_reply.started": "2025-05-25T16:31:46.799229Z",
          "shell.execute_reply": "2025-05-25T16:31:46.811584Z"
        },
        "id": "wr21RXt8XKS6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## 🧾 Code Block Overview\n",
        "\n",
        "This is a **Python script** that:\n",
        "- Loads the MNIST dataset (handwritten digits).\n",
        "- Preprocesses it.\n",
        "- Implements a **two-layer neural network from scratch** (no PyTorch or TensorFlow).\n",
        "- Trains it on the data.\n",
        "- Tests predictions and evaluates accuracy.\n",
        "\n",
        "We'll go **line-by-line**, explaining every function, loop, and concept.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔹 1. Import Libraries\n",
        "```python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "```\n",
        "- `numpy`: Used for fast numerical operations like matrix multiplication.\n",
        "- `pandas`: Used to load CSV files into tables (like Excel).\n",
        "- `matplotlib.pyplot`: Used to plot images and graphs.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔹 2. Load Data\n",
        "```python\n",
        "data = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\n",
        "```\n",
        "- This reads the MNIST training data (`train.csv`) which has over 42,000 rows of digit images.\n",
        "- Each row contains:\n",
        "  - One label (the actual digit: 0–9)\n",
        "  - Followed by 784 numbers representing pixel values of a 28x28 image.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔹 3. Convert to NumPy Array\n",
        "```python\n",
        "data = np.array(data)\n",
        "m, n = data.shape\n",
        "```\n",
        "- Converts the data into a NumPy array (easier to work with).\n",
        "- `m` = number of samples (rows), `n` = number of columns (785: 784 pixels + 1 label).\n",
        "\n",
        "---\n",
        "\n",
        "### 🔹 4. Shuffle Data\n",
        "```python\n",
        "np.random.shuffle(data)\n",
        "```\n",
        "- Shuffles the data so we don’t get biased results.\n",
        "- Important before splitting into training and validation sets.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔹 5. Split Validation Set (`dev`)\n",
        "```python\n",
        "data_dev = data[0:1000].T\n",
        "Y_dev = data_dev[0]\n",
        "X_dev = data_dev[1:n]\n",
        "X_dev = X_dev / 255.\n",
        "```\n",
        "- Takes first 1000 examples for validation/testing later.\n",
        "- `.T` transposes the data so each **column** is one example (instead of each row).\n",
        "- `Y_dev`: Extracts labels (first row).\n",
        "- `X_dev`: Extracts pixel data (remaining rows).\n",
        "- Normalize pixel values to range [0, 1] by dividing by 255.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔹 6. Split Training Set\n",
        "```python\n",
        "data_train = data[1000:m].T\n",
        "Y_train = data_train[0]\n",
        "X_train = data_train[1:n]\n",
        "X_train = X_train / 255.\n",
        "_, m_train = X_train.shape\n",
        "```\n",
        "- Uses rest of data (after 1000) for training.\n",
        "- Again transpose and separate labels and inputs.\n",
        "- Normalize input again.\n",
        "- `_`, `m_train`: ignore first value, store number of training examples.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 Neural Network Implementation\n",
        "\n",
        "Now comes the core of our neural network.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔹 7. Define Initial Parameters\n",
        "```python\n",
        "def init_params():\n",
        "    W1 = np.random.rand(10, 784) - 0.5\n",
        "    b1 = np.random.rand(10, 1) - 0.5\n",
        "    W2 = np.random.rand(10, 10) - 0.5\n",
        "    b2 = np.random.rand(10, 1) - 0.5\n",
        "    return W1, b1, W2, b2\n",
        "```\n",
        "- Initializes weights and biases randomly.\n",
        "- Shapes:\n",
        "  - `W1`: (10 x 784): Input → Hidden layer (10 units)\n",
        "  - `b1`: (10 x 1): Bias for hidden layer\n",
        "  - `W2`: (10 x 10): Hidden → Output layer\n",
        "  - `b2`: (10 x 1): Bias for output layer\n",
        "- Subtracts 0.5 to make values range from [-0.5, 0.5].\n",
        "\n",
        "---\n",
        "\n",
        "### 🔹 8. Activation Functions\n",
        "```python\n",
        "def ReLU(Z):\n",
        "    return np.maximum(Z, 0)\n",
        "\n",
        "def softmax(Z):\n",
        "    A = np.exp(Z) / sum(np.exp(Z))\n",
        "    return A\n",
        "```\n",
        "- **ReLU**: Returns max(0, Z). Introduces non-linearity.\n",
        "- **Softmax**: Turns raw outputs into probabilities that sum to 1.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔹 9. Forward Propagation\n",
        "```python\n",
        "def forward_prop(W1, b1, W2, b2, X):\n",
        "    Z1 = W1.dot(X) + b1\n",
        "    A1 = ReLU(Z1)\n",
        "    Z2 = W2.dot(A1) + b2\n",
        "    A2 = softmax(Z2)\n",
        "    return Z1, A1, Z2, A2\n",
        "```\n",
        "- Computes activations step by step.\n",
        "  - `Z1` = linear transformation of input using weights `W1`\n",
        "  - `A1` = apply ReLU\n",
        "  - `Z2` = linear transformation of hidden layer using `W2`\n",
        "  - `A2` = apply Softmax (final output)\n",
        "\n",
        "---\n",
        "\n",
        "### 🔹 10. Derivative of ReLU\n",
        "```python\n",
        "def ReLU_deriv(Z):\n",
        "    return Z > 0\n",
        "```\n",
        "- Returns 1 where Z > 0, else 0.\n",
        "- Used during backpropagation.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔹 11. One-Hot Encoding\n",
        "```python\n",
        "def one_hot(Y):\n",
        "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
        "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
        "    one_hot_Y = one_hot_Y.T\n",
        "    return one_hot_Y\n",
        "```\n",
        "- Converts labels like `[2, 1, 4]` into:\n",
        "  ```\n",
        "  [[0, 0, 1, ..., 0],\n",
        "   [0, 1, 0, ..., 0],\n",
        "   ...]\n",
        "  ```\n",
        "- Transpose so each column corresponds to one sample.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔹 12. Backward Propagation\n",
        "```python\n",
        "def backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y):\n",
        "    one_hot_Y = one_hot(Y)\n",
        "    dZ2 = A2 - one_hot_Y\n",
        "    dW2 = 1/m * dZ2.dot(A1.T)\n",
        "    db2 = 1/m * np.sum(dZ2)\n",
        "    dZ1 = W2.T.dot(dZ2) * ReLU_deriv(Z1)\n",
        "    dW1 = 1/m * dZ1.dot(X.T)\n",
        "    db1 = 1/m * np.sum(dZ1)\n",
        "    return dW1, db1, dW2, db2\n",
        "```\n",
        "- Calculates how much the error came from each weight.\n",
        "- Uses chain rule of derivatives to trace backwards.\n",
        "- These gradients tell us how to update weights to reduce error.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔹 13. Update Parameters\n",
        "```python\n",
        "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
        "    W1 = W1 - alpha * dW1\n",
        "    b1 = b1 - alpha * db1    \n",
        "    W2 = W2 - alpha * dW2  \n",
        "    b2 = b2 - alpha * db2    \n",
        "    return W1, b1, W2, b2\n",
        "```\n",
        "- Adjust weights and biases based on gradients.\n",
        "- `alpha` is the learning rate — controls how big the updates are.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔹 14. Get Final Predictions\n",
        "```python\n",
        "def get_predictions(A2):\n",
        "    return np.argmax(A2, 0)\n",
        "```\n",
        "- From final output (softmax), returns predicted class (digit 0–9).\n",
        "- `argmax` finds index with highest probability.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔹 15. Calculate Accuracy\n",
        "```python\n",
        "def get_accuracy(predictions, Y):\n",
        "    print(predictions, Y)\n",
        "    return np.sum(predictions == Y) / Y.size\n",
        "```\n",
        "- Compares predicted labels with true labels.\n",
        "- Returns percentage correct.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔹 16. Full Gradient Descent Loop\n",
        "```python\n",
        "def gradient_descent(X, Y, alpha, iterations):\n",
        "    W1, b1, W2, b2 = init_params()\n",
        "    for i in range(iterations):\n",
        "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
        "        dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y)\n",
        "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
        "        if i % 10 == 0:\n",
        "            print(\"Iteration: \", i)\n",
        "            predictions = get_predictions(A2)\n",
        "            print(get_accuracy(predictions, Y))\n",
        "    return W1, b1, W2, b2\n",
        "```\n",
        "- Runs all steps in a loop for fixed number of `iterations`.\n",
        "- Every 10 iterations, prints current iteration and accuracy.\n",
        "- Returns final trained weights and biases.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔹 17. Train Model\n",
        "```python\n",
        "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.10, 500)\n",
        "```\n",
        "- Trains model for 500 iterations with learning rate `0.1`.\n",
        "- Achieves ~85% accuracy on training set.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔹 18. Make Predictions Function\n",
        "```python\n",
        "def make_predictions(X, W1, b1, W2, b2):\n",
        "    _, _, _, A2 = forward_prop(W1, b1, W2, b2, X)\n",
        "    predictions = get_predictions(A2)\n",
        "    return predictions\n",
        "```\n",
        "- Takes new input `X` and makes prediction using trained weights.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔹 19. Test Prediction on Specific Image\n",
        "```python\n",
        "def test_prediction(index, W1, b1, W2, b2):\n",
        "    current_image = X_train[:, index, None]\n",
        "    prediction = make_predictions(X_train[:, index, None], W1, b1, W2, b2)\n",
        "    label = Y_train[index]\n",
        "    print(\"Prediction: \", prediction)\n",
        "    print(\"Label: \", label)\n",
        "    current_image = current_image.reshape((28, 28)) * 255\n",
        "    plt.gray()\n",
        "    plt.imshow(current_image, interpolation='nearest')\n",
        "    plt.show()\n",
        "```\n",
        "- Shows image at given `index`, its predicted label, and actual label.\n",
        "- Displays grayscale image using matplotlib.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔹 20. Evaluate on Dev Set\n",
        "```python\n",
        "dev_predictions = make_predictions(X_dev, W1, b1, W2, b2)\n",
        "get_accuracy(dev_predictions, Y_dev)\n",
        "```\n",
        "- After training, run predictions on dev set.\n",
        "- Check generalization accuracy (~84%).\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ Summary Table\n",
        "\n",
        "| Part | What It Does |\n",
        "|------|---------------|\n",
        "| `init_params()` | Starts with random weights |\n",
        "| `forward_prop()` | Makes a prediction |\n",
        "| `backward_prop()` | Figures out how wrong the prediction was |\n",
        "| `update_params()` | Adjusts weights to improve next guess |\n",
        "| `gradient_descent()` | Loops above steps many times to train |\n",
        "| `make_predictions()` | Make predictions on new data |\n",
        "| `test_prediction()` | Show prediction vs truth visually |\n",
        "\n",
        "---\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "WupnJ7E9XKS7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "IXkp5z_TXKS8"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}